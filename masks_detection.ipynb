{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "masks-detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPbZgGJTxapaHCd4DdM42CB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jungfrau70/encore-4team/blob/main/masks_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3AHYID8UfQk"
      },
      "source": [
        "## Masks Detection Web Service\n",
        "\n",
        "https://masks-detection-13237.web.app\n",
        "\n",
        "https://github.com/ohyicong/masksdetection.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILDo1RpZXnKh"
      },
      "source": [
        "# Download Code from GITHUB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c4grhh5UbyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb96726-42b3-4ec5-c042-12f09244d2ef"
      },
      "source": [
        "!git clone https://github.com/ohyicong/masksdetection.git/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'masksdetection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNL0NDqkZ9rZ"
      },
      "source": [
        "## STEP 1. import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K4Ul904Z8Pw"
      },
      "source": [
        "# USAGE\n",
        "# python train_mask_detector.py --dataset dataset\n",
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9n8CDToaE9a"
      },
      "source": [
        "## STEP 2. 전처리 (pre-processing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj5PPLs7aIOk",
        "outputId": "e6b6c18a-2a37-4083-fd62-f680e7d97155"
      },
      "source": [
        "print(os.getcwd())\n",
        "!ls -al masksdetection"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 10904\n",
            "drwxr-xr-x 13 root root     4096 May 29 15:13 .\n",
            "drwxr-xr-x  1 root root     4096 May 29 14:48 ..\n",
            "-rw-r--r--  1 root root       93 May 29 15:11 checkpoint\n",
            "-rw-r--r--  1 root root     5788 May 29 14:49 create_augmented_dataset.py\n",
            "drwxr-xr-x  4 root root     4096 May 29 14:49 dataset\n",
            "-rw-r--r--  1 root root     4848 May 29 14:49 detect_mask_video.py\n",
            "-rw-r--r--  1 root root     1059 May 29 14:49 detect_mask_video.spec\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 face_detector\n",
            "drwxr-xr-x  8 root root     4096 May 29 14:49 .git\n",
            "-rw-r--r--  1 root root       28 May 29 14:49 .gitignore\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 images\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 .ipynb_checkpoints\n",
            "drwxr-xr-x 12 root root     4096 May 29 15:13 masksdetection\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 model\n",
            "-rw-r--r--  1 root root 11043490 May 29 15:11 my_checkpoint.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 root root    17711 May 29 15:11 my_checkpoint.ckpt.index\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 plot\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 __pycache__\n",
            "-rw-r--r--  1 root root     7445 May 29 14:49 requirements.txt\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 sounds\n",
            "-rw-r--r--  1 root root     5134 May 29 14:49 train_mask_detector.py\n",
            "drwxr-xr-x  4 root root     4096 May 29 14:49 web_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRyd8WhxbDME",
        "outputId": "a20f6f6c-90ab-4a76-d4e6-874acbd97b59"
      },
      "source": [
        "import os\n",
        "os.chdir('masksdetection')\n",
        "!ls -al ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 10904\n",
            "drwxr-xr-x 13 root root     4096 May 29 15:13 .\n",
            "drwxr-xr-x  1 root root     4096 May 29 14:48 ..\n",
            "-rw-r--r--  1 root root       93 May 29 15:11 checkpoint\n",
            "-rw-r--r--  1 root root     5788 May 29 14:49 create_augmented_dataset.py\n",
            "drwxr-xr-x  4 root root     4096 May 29 14:49 dataset\n",
            "-rw-r--r--  1 root root     4848 May 29 14:49 detect_mask_video.py\n",
            "-rw-r--r--  1 root root     1059 May 29 14:49 detect_mask_video.spec\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 face_detector\n",
            "drwxr-xr-x  8 root root     4096 May 29 14:49 .git\n",
            "-rw-r--r--  1 root root       28 May 29 14:49 .gitignore\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 images\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 .ipynb_checkpoints\n",
            "drwxr-xr-x 12 root root     4096 May 29 15:13 masksdetection\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 model\n",
            "-rw-r--r--  1 root root 11043490 May 29 15:11 my_checkpoint.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 root root    17711 May 29 15:11 my_checkpoint.ckpt.index\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 plot\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 __pycache__\n",
            "-rw-r--r--  1 root root     7445 May 29 14:49 requirements.txt\n",
            "drwxr-xr-x  2 root root     4096 May 29 14:49 sounds\n",
            "-rw-r--r--  1 root root     5134 May 29 14:49 train_mask_detector.py\n",
            "drwxr-xr-x  4 root root     4096 May 29 14:49 web_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_F6hzOOsiWd"
      },
      "source": [
        "# construct the argument parser and parse the arguments\n",
        "dataset_path=os.getcwd()+\"//dataset\"\n",
        "model_path=os.getcwd()+\"//model//mask_model\"\n",
        "plot_path=os.getcwd()+\"//plot\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPiCu7LTnUd8"
      },
      "source": [
        "training_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    # 위의 옵션 값들을 보고 적절히 대입하여 줍니다.\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,  \n",
        "    width_shift_range=0.2, \n",
        "    height_shift_range=0.2, \n",
        "    shear_range=0.15, \n",
        "    horizontal_flip=True, \n",
        "    fill_mode='nearest', \n",
        "    validation_split=0.2\n",
        "    )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-5x2C-MoAQX"
      },
      "source": [
        "TRAINING_DIR = \"dataset/\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkFhXkLxoiBl",
        "outputId": "8a5b411a-e393-45f9-dff9-966f6b673264"
      },
      "source": [
        "training_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                            target_size=(224, 224),\n",
        "                                                            color_mode='rgb', classes=None,\n",
        "                                                            class_mode='categorical',\n",
        "                                                            batch_size=128,                                                            \n",
        "                                                            subset='training', \n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1131 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpoAB-TDrM8F",
        "outputId": "af9dba9d-ecfc-422e-911a-e16c84ef1f7e"
      },
      "source": [
        "validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                            target_size=(224, 224),\n",
        "                                                            color_mode='rgb', classes=None,\n",
        "                                                            class_mode='categorical',\n",
        "                                                            batch_size=128,                                                            \n",
        "                                                            subset='validation', \n",
        "                                                            )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 282 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olu2e3RAb-Be"
      },
      "source": [
        "## STEP 3. 모델 정의 (Sequential)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtD7VdsFcayk",
        "outputId": "4363be2c-3b94-4301-d817-d31558d06ea3"
      },
      "source": [
        "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
        "# left off\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHe2YJWwcdKR"
      },
      "source": [
        "## STEP 4. optimizer, loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvsd_Q2TsuWo"
      },
      "source": [
        "# initialize the initial learning rate, number of epochs to train for,\n",
        "# and batch size\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 20\n",
        "BS = 32"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuZPGgu6dE6i",
        "outputId": "f6d6560a-a3ef-4c50-f072-eaecfe16301b"
      },
      "source": [
        "# compile our model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyurl9b8dANW"
      },
      "source": [
        "## STEP 5. ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQTpk-pYg9qr"
      },
      "source": [
        "checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=True, \n",
        "                             save_best_only=True, \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26jNHE7FdL4F"
      },
      "source": [
        "## STEP 6. 학습 (fit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPR0ZWvPqB88",
        "outputId": "8b710e5a-942f-470f-ddc1-cd1e396528fa"
      },
      "source": [
        "H = model.fit(training_generator,\n",
        "          epochs=BS, \n",
        "          verbose=1, \n",
        "          callbacks=[checkpoint],\n",
        "          validation_data=(validation_generator)\n",
        "          )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "9/9 [==============================] - 23s 2s/step - loss: 0.8473 - acc: 0.5712 - val_loss: 0.3482 - val_acc: 0.9043\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.34817, saving model to my_checkpoint.ckpt\n",
            "Epoch 2/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.3692 - acc: 0.8311 - val_loss: 0.1480 - val_acc: 0.9787\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.34817 to 0.14803, saving model to my_checkpoint.ckpt\n",
            "Epoch 3/32\n",
            "9/9 [==============================] - 16s 2s/step - loss: 0.1763 - acc: 0.9416 - val_loss: 0.0977 - val_acc: 0.9823\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.14803 to 0.09765, saving model to my_checkpoint.ckpt\n",
            "Epoch 4/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.1176 - acc: 0.9637 - val_loss: 0.0729 - val_acc: 0.9823\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.09765 to 0.07293, saving model to my_checkpoint.ckpt\n",
            "Epoch 5/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0788 - acc: 0.9805 - val_loss: 0.0614 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.07293 to 0.06141, saving model to my_checkpoint.ckpt\n",
            "Epoch 6/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0774 - acc: 0.9708 - val_loss: 0.0578 - val_acc: 0.9823\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.06141 to 0.05783, saving model to my_checkpoint.ckpt\n",
            "Epoch 7/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0602 - acc: 0.9823 - val_loss: 0.0434 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.05783 to 0.04343, saving model to my_checkpoint.ckpt\n",
            "Epoch 8/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0628 - acc: 0.9805 - val_loss: 0.0387 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.04343 to 0.03868, saving model to my_checkpoint.ckpt\n",
            "Epoch 9/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0523 - acc: 0.9823 - val_loss: 0.0313 - val_acc: 0.9965\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.03868 to 0.03125, saving model to my_checkpoint.ckpt\n",
            "Epoch 10/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0472 - acc: 0.9894 - val_loss: 0.0347 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.03125\n",
            "Epoch 11/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0479 - acc: 0.9850 - val_loss: 0.0529 - val_acc: 0.9858\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.03125\n",
            "Epoch 12/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0442 - acc: 0.9859 - val_loss: 0.0321 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.03125\n",
            "Epoch 13/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0479 - acc: 0.9867 - val_loss: 0.0322 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.03125\n",
            "Epoch 14/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0346 - acc: 0.9929 - val_loss: 0.0280 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.03125 to 0.02803, saving model to my_checkpoint.ckpt\n",
            "Epoch 15/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0360 - acc: 0.9903 - val_loss: 0.0297 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02803\n",
            "Epoch 16/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0324 - acc: 0.9920 - val_loss: 0.0290 - val_acc: 0.9965\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.02803\n",
            "Epoch 17/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0276 - acc: 0.9894 - val_loss: 0.0244 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.02803 to 0.02437, saving model to my_checkpoint.ckpt\n",
            "Epoch 18/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0302 - acc: 0.9876 - val_loss: 0.0253 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02437\n",
            "Epoch 19/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0236 - acc: 0.9956 - val_loss: 0.0297 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.02437\n",
            "Epoch 20/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0290 - acc: 0.9929 - val_loss: 0.0318 - val_acc: 0.9858\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.02437\n",
            "Epoch 21/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0200 - acc: 0.9903 - val_loss: 0.0192 - val_acc: 0.9965\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.02437 to 0.01923, saving model to my_checkpoint.ckpt\n",
            "Epoch 22/32\n",
            "9/9 [==============================] - 16s 2s/step - loss: 0.0253 - acc: 0.9903 - val_loss: 0.0257 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01923\n",
            "Epoch 23/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0193 - acc: 0.9947 - val_loss: 0.0272 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.01923\n",
            "Epoch 24/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.0241 - val_acc: 0.9965\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01923\n",
            "Epoch 25/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0126 - acc: 0.9973 - val_loss: 0.0344 - val_acc: 0.9858\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01923\n",
            "Epoch 26/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0297 - acc: 0.9929 - val_loss: 0.0199 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01923\n",
            "Epoch 27/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0204 - acc: 0.9920 - val_loss: 0.0188 - val_acc: 1.0000\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.01923 to 0.01883, saving model to my_checkpoint.ckpt\n",
            "Epoch 28/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0186 - acc: 0.9973 - val_loss: 0.0351 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01883\n",
            "Epoch 29/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0166 - acc: 0.9973 - val_loss: 0.0204 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01883\n",
            "Epoch 30/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0184 - acc: 0.9947 - val_loss: 0.0232 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01883\n",
            "Epoch 31/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0192 - acc: 0.9938 - val_loss: 0.0239 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.01883\n",
            "Epoch 32/32\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0127 - acc: 0.9982 - val_loss: 0.0235 - val_acc: 0.9929\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddb213U0dS9m"
      },
      "source": [
        "## STEP 7. 학습 완료 후 Load Weights (ModelCheckpoint)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjTJB3wms2Ri",
        "outputId": "1939c8af-2c3d-499e-d571-4ebcedf8ff4d"
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe18a6539d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZV37dFKdbQ0"
      },
      "source": [
        "## STEP 8. 예측 (Predict)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd2sDK7Lec3x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "797876ac-83a7-4c4a-8b29-f7e8b99359cf"
      },
      "source": [
        "# make predictions on the testing set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fef800d1b2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make predictions on the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] evaluating network...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredIdxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'testX' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC287h1heVbI"
      },
      "source": [
        "## STEP 9. 리포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "pyI2nKm0YJHA",
        "outputId": "1a435f83-d63d-4f26-92b6-a3bf3242f192"
      },
      "source": [
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(plot_path)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c19f1bdaf793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# for each image in the testing set we need to find the index of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# label with corresponding largest predicted probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredIdxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredIdxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# show a nicely formatted classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predIdxs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfwIO1wxemX_"
      },
      "source": [
        "## STEP 10. 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_YVmWCpeyDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cfd461-565c-45fa-c463-b7a1958b1584"
      },
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model... path: %s\"%(model_path+\".h5\"))\n",
        "model.save(model_path+\".h5\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] saving mask detector model... path: /content/masksdetection//model//mask_model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}