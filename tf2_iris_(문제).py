# -*- coding: utf-8 -*-
"""TF2-iris (문제).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17PCklsIBWRYXDeXiC_GQzYNHlKT-ebR2
"""

# ======================================================================
# There are 5 questions in this test with increasing difficulty from 1-5
# Please note that the weight of the grade for the question is relative
# to its difficulty. So your Category 1 question will score much less
# than your Category 5 question.
# ======================================================================
#
# Basic Datasets question
#
# For this task you will train a classifier for Iris flowers using the Iris dataset
# The final layer in your neural network should look like: tf.keras.layers.Dense(3, activation=tf.nn.softmax)
# The input layer will expect data in the shape (4,)
# We've given you some starter code for preprocessing the data
# You'll need to implement the preprocess function for data.map

# =========== 합격 기준 가이드라인 공유 ============= #
# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #
# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #
# =================================================== #
# 문제명: Category 2 - iris
# val_loss: 0.14
# val_acc: 0.93
# =================================================== #
# =================================================== #


import tensorflow as tf
import tensorflow_datasets as tfds

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import ModelCheckpoint

# data = tfds.load("iris", split=tfds.Split.TRAIN.subsplit(tfds.percent[:80]))
train_dataset = tfds.load('iris', split='train[:80%]')
valid_dataset = tfds.load('iris', split='train[80%:]')

def preprocess(data):
    # YOUR CODE HERE
    # Should return features and one-hot encoded labels
    x = data['features']
    y = data['label']
    y = tf.one_hot(y, depth=3)
    return x, y


def solution_model():
    train_ds = train_dataset.map(preprocess).batch(10)
    valid_ds = valid_dataset.map(preprocess).batch(10)

    model = Sequential([
        Dense(64, activation='tanh', input_shape=[4]),
        # Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(3, activation='softmax'),
    ])

    model.summary()

    adam = tf.keras.optimizers.Adam(
        learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False
    )
    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])

    checkpoint_path = "my_checkpoing.ckpt"
    checkpoint = ModelCheckpoint(filepath=checkpoint_path, 
                                monitor='val_loss', 
                                verbose=1, 
                                save_best_only=True, 
                                save_weights_only=True,)

    model.fit(
            train_ds,
            epochs=30, 
            verbose=1, 
            callbacks=[checkpoint], 
            validation_data=(valid_ds)
            )

    model.load_weights(checkpoint_path)

    return model


# Note that you'll need to save your model as a .h5 like this
# This .h5 will be uploaded to the testing infrastructure
# and a score will be returned to you
if __name__ == '__main__':
    model = solution_model()
    model.save("TF2-iris.h5")

"""# 새 섹션"""

valid_ds = valid_dataset.map(preprocess).batch(10)
model = tf.keras.models.load_model("TF2-iris.h5")
model.evaluate(valid_ds)